# -*- coding: utf-8 -*-
"""CSE425 Project_22101025

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LVvET6rWha_r9O9c7EyVx0nauWiDc8vp
"""

!pip install pyarrow
import pandas as pd

file_path = "train-00000-of-00001.parquet"

try:
    train_df = pd.read_parquet(file_path)
    print("Loaded as Parquet")
    print(train_df.head())  # Preview
except Exception as e:
    print("Parquet load failed:", e)


    try:
        train_df = pd.read_csv(file_path)
        print("Loaded as CSV")
        print(train_df.head())
    except Exception as e_csv:
        print("CSV load also failed:", e_csv)

!pip install -q torch torchvision scikit-learn matplotlib seaborn umap-learn

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import numpy as np
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

#dataset
transform = transforms.ToTensor()
train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)
test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)

#samples
examples = next(iter(train_loader))[0][:8]
fig, axes = plt.subplots(1, 8, figsize=(12, 2))
for i in range(8):
    axes[i].imshow(examples[i][0], cmap="gray")
    axes[i].axis("off")
plt.suptitle("Sample MNIST Digits")
plt.show()

class ConvAutoencoder(nn.Module):
    def __init__(self, latent_dim=64):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 32, 3, stride=2, padding=1),  # 14x14
            nn.ReLU(),
            nn.Conv2d(32, 64, 3, stride=2, padding=1),  # 7x7
            nn.ReLU(),
            nn.Flatten(),
            nn.Linear(64*7*7, latent_dim)
        )
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 64*7*7),
            nn.ReLU(),
            nn.Unflatten(1, (64, 7, 7)),
            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(32, 1, 3, stride=2, padding=1, output_padding=1),
            nn.Sigmoid()
        )

    def forward(self, x):
        z = self.encoder(x)
        x_recon = self.decoder(z)
        return x_recon

    def embed(self, x):
        return self.encoder(x)


model = ConvAutoencoder(latent_dim=64).to(device)
optimizer = optim.Adam(model.parameters(), lr=1e-3)
loss_fn = nn.MSELoss()

print("Pre-training autoencoder...")
for epoch in range(10):
    model.train()
    total_loss = 0
    for x, _ in train_loader:
        x = x.to(device)
        x_recon = model(x)
        loss = loss_fn(x_recon, x)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f"Epoch {epoch+1}: Loss = {total_loss / len(train_loader):.4f}")


def target_distribution(q):
    weight = q ** 2 / q.sum(0)
    return (weight.T / weight.sum(1)).T

#extract embeddings
model.eval()
embeddings = []
labels = []
with torch.no_grad():
    for x, y in train_loader:
        x = x.to(device)
        z = model.embed(x)
        embeddings.append(z.cpu())
        labels.extend(y)
embeddings = torch.cat(embeddings).numpy()
labels = np.array(labels)

kmeans = KMeans(n_clusters=10, n_init=20)
y_pred = kmeans.fit_predict(embeddings)
cluster_centers = torch.tensor(kmeans.cluster_centers_, dtype=torch.float, device=device)

#clusrter loss
def clustering_loss(z, cluster_centers):
    alpha = 1.0
    q = 1.0 / (1.0 + torch.sum((z.unsqueeze(1) - cluster_centers)**2, dim=2) / alpha)
    q = (q.T / q.sum(1)).T
    p = target_distribution(q.detach().cpu().numpy())
    p = torch.tensor(p, dtype=torch.float, device=device)
    return torch.nn.functional.kl_div(q.log(), p, reduction='batchmean'), q

#tuning encoder
print("Fine-tuning clustering...")
for epoch in range(10):
    model.train()
    total_loss = 0
    for x, _ in train_loader:
        x = x.to(device)
        z = model.embed(x)
        loss, _ = clustering_loss(z, cluster_centers)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f"Clustering Epoch {epoch+1}: KL Loss = {total_loss / len(train_loader):.4f}")

#recompute
model.eval()
embeddings = []
with torch.no_grad():
    for x, _ in test_loader:
        x = x.to(device)
        z = model.embed(x)
        embeddings.append(z.cpu())
embeddings = torch.cat(embeddings).numpy()

final_preds = KMeans(n_clusters=10).fit_predict(embeddings)

#eval
print("Silhouette Score:", silhouette_score(embeddings, final_preds))
print("Davies-Bouldin Index:", davies_bouldin_score(embeddings, final_preds))
print("Calinski-Harabasz Index:", calinski_harabasz_score(embeddings, final_preds))

#PCA
pca = PCA(n_components=2)
pca_result = pca.fit_transform(embeddings)
plt.figure(figsize=(6, 5))
sns.scatterplot(x=pca_result[:,0], y=pca_result[:,1], hue=final_preds, palette='tab10', s=10)
plt.title("PCA of Clustered Embeddings")
plt.legend([],[], frameon=False)
plt.show()

#t-SNE
tsne = TSNE(n_components=2, perplexity=30)
tsne_result = tsne.fit_transform(embeddings[:2000])
plt.figure(figsize=(6, 5))
sns.scatterplot(x=tsne_result[:,0], y=tsne_result[:,1], hue=final_preds[:2000], palette='tab10', s=10)
plt.title("t-SNE of Clustered Embeddings")
plt.legend([],[], frameon=False)
plt.show()

from torchview import draw_graph
!pip install graphviz


model_cpu = ConvAutoencoder(latent_dim=64).to('cpu')

model_graph = draw_graph(
    model_cpu,
    input_size=(2, 1, 28, 28),
    hide_inner_tensors=False,
    hide_module_functions=False,
    expand_nested=True,
)

model_graph.visual_graph

model_graph.visual_graph.render("model_graph", format="png", cleanup=True)